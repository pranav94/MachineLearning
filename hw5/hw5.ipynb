{"cells":[{"cell_type":"markdown","source":[" # 1. Clustering\n"," ## 1.1 Visualizing the data"],"metadata":{}},{"source":["import random\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import mltools as ml\n","from scipy import linalg\n","\n","iris = np.genfromtxt(\"data/iris.txt\", delimiter=None)\n","X, Y = iris[:, :2], iris[:, -1]\n","plt.scatter(iris[:, 0], iris[:, 1])\n","plt.xlabel('Feature 1')\n","plt.ylabel('Feature 2')\n","plt.title(\"Iris Dataset\")\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Possibly 4 clusters here.\n"," ## 1.2"],"metadata":{}},{"source":["random.seed(0)\n","initializations = [\n","    X[[0, 1], :],\n","    X[[37, 111], :],\n","    'random',\n","    'farthest',\n","    'k++'\n","]\n","k = 2\n","\n","Z, C, S = 0, 0, 0\n","max_score = 0\n","for index, init in enumerate(initializations):\n","    (z, c, sumd) = ml.cluster.kmeans(X, k, init=init, max_iter=100)\n","    if sumd > max_score:\n","        max_score = sumd\n","        (Z, C, S) = (z, c, sumd)\n","\n","    print(\"Score for assignment: #{}: {}\".format(index+1, sumd))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" They all seem to have the similar squared sum on distances. However, #4 and #5 seems to be the largest."],"metadata":{}},{"source":["\n","ml.plotClassify2D(None, X, Z)\n","plt.scatter(C[:, 0], C[:, 1], color='red', label='Cluster centers')\n","plt.title('k=2 means clustering with the best assignment as demonstrated above.')\n","plt.xlabel('Feature 1')\n","plt.ylabel('Feature 2')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["initializations = [\n","    X[[0, 1, 2, 3, 4], :],\n","    X[[24, 48, 72, 96, 120], :],\n","    'random',\n","    'farthest',\n","    'k++'\n","]\n","k = 5\n","\n","Z, C, S = 0, 0, 0\n","max_score = 0\n","for index, init in enumerate(initializations):\n","    (z, c, sumd) = ml.cluster.kmeans(X, k, init=init, max_iter=100)\n","    if sumd > max_score:\n","        max_score = sumd\n","        (Z, C, S) = (z, c, sumd)\n","\n","    print(\"Score for assignment: #{}: {}\".format(index+1, sumd))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Assignment #5 seems to be best assignment."],"metadata":{}},{"source":["\n","ml.plotClassify2D(None, X, Z)\n","plt.scatter(C[:, 0], C[:, 1], color='red', label='Cluster centers')\n","plt.title('k=5 means clustering with the best assignment as demonstrated above.')\n","plt.xlabel('Feature 1')\n","plt.ylabel('Feature 2')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["initializations = [\n","    X[list(range(20)), :],\n","    X[list(range(0, 140, 7)), :],\n","    'random',\n","    'farthest',\n","    'k++'\n","]\n","k = 20\n","\n","Z, C, S = 0, 0, 0\n","max_score = 0\n","for index, init in enumerate(initializations):\n","    (z, c, sumd) = ml.cluster.kmeans(X, k, init=init, max_iter=100)\n","    if sumd > max_score:\n","        max_score = sumd\n","        (Z, C, S) = (z, c, sumd)\n","\n","    print(\"Score for assignment: #{}: {}\".format(index+1, sumd))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Assignment #1 seems to be the best assignment."],"metadata":{}},{"source":["ml.plotClassify2D(None, X, Z)\n","plt.scatter(C[:, 0], C[:, 1], color='red', label='Cluster centers')\n","plt.title('k=20 means clustering with the best assignment as demonstrated above.')\n","plt.xlabel('Feature 1')\n","plt.ylabel('Feature 2')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 1.3 Run agglomerative clustering on the data, using single linkage and then again using complete linkage."],"metadata":{}},{"source":["for k in [2, 5, 20]:\n","    (z, _) = ml.cluster.agglomerative(X, k, method='min')\n","    ml.plotClassify2D(None, X, z)\n","    plt.title('Agglomerative Clustering For K = {} and Single Linkage'.format(k))\n","    plt.xlabel('Feature 1')\n","    plt.ylabel('Feature 2')\n","    plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["for k in [2, 5, 20]:\n","    (z, _) = ml.cluster.agglomerative(X, k, method='max')\n","    ml.plotClassify2D(None, X, z)\n","    plt.title('Agglomerative Clustering For K = {} and Complete Linkage'.format(k))\n","    plt.xlabel('Feature 1')\n","    plt.ylabel('Feature 2')\n","    plt.show()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" For k = 2, K means has more meaningful clusters. Complete linkage comes close to this but single linkage has very few data points in one cluster.\n","\n"," For k = 5, Both single linkage agglomerative and complete linkage agglomerative have good clustering with complete linkage slightly better, while K means shows some extent of overfitting.\n","\n"," For k = 20, K means shows clear overfitting while agglomerative shows better clustering.\n","\n"," K means clusters outliers well. But agglomerative classifies these outliers as a new cluster."],"metadata":{}},{"cell_type":"markdown","source":[" # 2. EigenFaces"],"metadata":{}},{"source":["X = np.genfromtxt(\"data/faces.txt\", delimiter=None)  # load face dataset\n","plt.figure()\n","img = np.reshape(X[6, :], (24, 24))\n","plt.imshow(img.T, cmap=\"gray\")  # display image patch; you may have to squint\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 2.1 Plot the mean"],"metadata":{}},{"source":["mean = np.mean(X, axis=0)\n","X0 = X - mean\n","img = np.reshape(mean, (24, 24))\n","plt.imshow(img.T, cmap=\"gray\")\n","plt.title(\"Mean of the Face\")\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 2.2  SVD of the data"],"metadata":{}},{"source":["U, s, Vh = linalg.svd(X0, full_matrices=False)\n","W = np.dot(U, np.diag(s))\n","print(\"Shape of W: {}\".format(W.shape))\n","print(\"Shape of Vh: {}\".format(Vh.shape))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 2.3 For K = 1 . . . 10, compute the approximation to X0 given by the first K eigendirections."],"metadata":{}},{"source":["\n","K = range(0, 10, 1)\n","mse = [\n","    np.mean(\n","        (\n","            X0 - np.dot(W[:, :k], Vh[:k, :])\n","        )**2\n","    )\n","    for k in K\n","]\n","\n","plt.plot(K, mse)\n","plt.xlabel('K')\n","plt.ylabel('MSE')\n","plt.title('MSE vs K')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 2.4 Display the first three principal directions of the data"],"metadata":{}},{"source":["for j in range(3):\n","    alpha = 2*np.median(np.abs(W[:, j]))\n","    img = np.reshape(mean+alpha*Vh[j, :], (24, 24))\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(img.T, cmap='gray')\n","    plt.title('Principal Direction: {} (+alpha)'.format(j+1))\n","\n","    img = np.reshape(mean-alpha*Vh[j, :], (24, 24))\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(img.T, cmap='gray')\n","    plt.title('Principal Direction: {} (-alpha)'.format(j+1))\n","    plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 2.5 Reconstruct two images"],"metadata":{}},{"source":["for i in (10, 40):\n","    for k in (5, 10, 50, 100):\n","        plt.subplot(1, 2, 1)\n","        image = np.reshape(X[i, :], (24, 24))\n","        plt.title('Original Image #{}'.format(i))\n","        plt.imshow(image.T, cmap='gray')\n","\n","        image = np.reshape(np.dot(W[i, :k], Vh[:k]) + mean, (24, 24))\n","        plt.subplot(1, 2, 2)\n","        plt.title('Reconstructed Image #{} (K = {})'.format(i, k))\n","        plt.imshow(image.T, cmap='gray')\n","        plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 2.6 Latent representation"],"metadata":{}},{"source":["idx = random.sample(range(0, X.shape[0]), 25)\n","coord, params = ml.transforms.rescale(W[:, 0:2])\n","for i in idx:\n","    loc = (\n","        coord[i, 0], coord[i, 0]+0.5, coord[i, 1],\n","        coord[i, 1]+0.5\n","    ) \n","    img = np.reshape(X[i, :], (24, 24))\n","    plt.imshow(img.T, cmap=\"gray\", extent=loc)  # draw each image\n","    plt.title('Latent Space Plot')\n","    plt.axis((-2, 2, -2, 2))\n","plt.xlabel('X Axis')\n","plt.ylabel('Y Axis')\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # Statement of collaboration\n"," I have not collaborated with anyone for this homework."],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}