{"cells":[{"cell_type":"markdown","source":[" # Problem 1: Python & Data Exploration"],"metadata":{}},{"source":["import numpy as np\n","import matplotlib.pyplot as pt\n","\n","iris = np.genfromtxt(\"iris.txt\")\n","Y = iris[:, -1]\n","X = iris[:, :-1]\n","\n","data_points, features = X.shape\n","data_points, features"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 1. Data points and features\n","\n"," Number of data points: 148\n","\n"," Number of features: 4"],"metadata":{}},{"cell_type":"markdown","source":[" ## 2. Histogram of values"],"metadata":{}},{"source":["_fig, plots = pt.subplots(1, features, figsize=(10, 3))\n","for i in range(features):\n","    plots[i].hist(X[:, i])\n","    plots[i].set_xlabel(\"Feature-{}\".format(i))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 3. Mean and SD of features"],"metadata":{}},{"source":["for i in range(features):\n","    print(\"Feature {}: Mean = {}, SD = {}\".format(\n","        i, np.mean(X[:, i]), np.std(X[:, i]))\n","    )\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 4. Scatter plot for pairs of features"],"metadata":{}},{"source":["_fig, plots = pt.subplots(1, 3, figsize=(10, 3),)\n","for index, (x, y) in enumerate(((1, 2), (1, 3), (1, 4))):\n","    plots[index].scatter(x=X[:, x-1], y=X[:, y-1], c=Y[:])\n","    plots[index].set_xlabel(\"Features: ({}, {})\".format(x, y))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # Problem 2:  kNN predictions"],"metadata":{}},{"cell_type":"markdown","source":[" ## 1. Classification boundary for varying values of K = [1, 5, 10, 50] for features (1, 2)"],"metadata":{}},{"source":["import mltools as ml\n","np.random.seed(0)\n","X, Y = ml.shuffleData(X, Y)\n","Xtr, Xva, Ytr, Yva = ml.splitData(X[:, :2], Y, 0.75)\n","knn = ml.knn.knnClassify()\n","for K in (1, 5, 10, 50):\n","    knn.train(Xtr, Ytr, K)\n","    ml.plotClassify2D(knn, Xtr, Ytr)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## 2. The error rate (number of misclassifications) on both the training and validation data as a function of K = [1, 2, 5, 10, 50, 100, 200] for features (1, 2)."],"metadata":{}},{"source":["Xtr, Xva, Ytr, Yva = ml.splitData(X[:, :2], Y, 0.75)\n","K_values = [1, 2, 5, 10, 50, 100, 200]\n","errTrain = [0] * len(K_values)\n","errVal = [0] * len(K_values)\n","for i, K in enumerate(K_values):\n","    learner = ml.knn.knnClassify(Xtr, Ytr, K)\n","    YvaHat = learner.predict(Xva)\n","    YtrHat = learner.predict(Xtr)\n","    errTrain[i] = np.mean(YtrHat != Ytr)\n","    errVal[i] = np.mean(YvaHat != Yva)\n","\n","pt.semilogx(\n","    K_values, errTrain, 'red', marker='x',\n","    label='Training set error rate'\n",")\n","pt.semilogx(\n","    K_values, errVal, 'green', marker='o',\n","    label='Validation set error rate'\n",")\n","pt.legend()\n","pt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Looking at the plots, **K = 50** has the ideal range for model complexity. Hence **K=50** is the recommended value for the features (1,2)."],"metadata":{}},{"cell_type":"markdown","source":[" ## 3. The error rate (number of misclassifications) on both the training and validation data as a function of K = [1, 2, 5, 10, 50, 100, 200] for all features."],"metadata":{}},{"source":["Xtr, Xva, Ytr, Yva = ml.splitData(X, Y, 0.75)\n","errTrain = [0] * len(K_values)\n","errVal = [0] * len(K_values)\n","for i, K in enumerate(K_values):\n","    learner = ml.knn.knnClassify(Xtr, Ytr, K)\n","    YvaHat = learner.predict(Xva)\n","    YtrHat = learner.predict(Xtr)\n","    errTrain[i] = np.mean(YtrHat != Ytr)\n","    errVal[i] = np.mean(YvaHat != Yva)\n","\n","pt.semilogx(\n","    K_values, errTrain, 'red', marker='x',\n","    label='Training set error rate'\n",")\n","pt.semilogx(\n","    K_values, errVal, 'green', marker='o',\n","    label='Validation set error rate'\n",")\n","pt.legend()\n","pt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Looking at the plots, **K = 10** has the ideal range for model complexity. Hence **K=10** is the recommended value for all the features."],"metadata":{}},{"cell_type":"markdown","source":[" # Problem 3: Na√Øve Bayes Classifiers"],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}